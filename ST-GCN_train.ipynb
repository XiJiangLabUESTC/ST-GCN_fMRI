{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import io\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from ST_GCN import Model\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from EarlyStopping import EarlyStopping\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(adj_hat_path_):\n",
    "    temp_k=7\n",
    "    net = Model(1, 2, True, temp_k, adj_hat_path_)\n",
    "    net=net.to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    return net, optimizer\n",
    "\n",
    "def train_model(net,optimizer,criterion,train_dataloader):\n",
    "    training_loss,train_acc = 0.0,0.0\n",
    "    net.train()\n",
    "    for data, label in train_dataloader:\n",
    "        data=data.to(device)\n",
    "        label=label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(data)\n",
    "        loss = criterion(outputs, label.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        outputs = outputs.argmax(dim=1).data.cpu().numpy()\n",
    "        train_acc+=np.mean(outputs == label.cpu().numpy())\n",
    "    return train_acc/len(train_dataloader),training_loss/len(train_dataloader)\n",
    "\n",
    "def test_model(net,criterion,test_dataloader):\n",
    "    test_loss,test_acc = 0.0,0.0\n",
    "    net.eval()\n",
    "    for data, label in test_dataloader:\n",
    "        data=data.to(device)\n",
    "        label=label.to(device)\n",
    "        outputs = net(data)\n",
    "        test_loss +=criterion(outputs, label.long()).item()\n",
    "        outputs = outputs.argmax(dim=1).data.cpu().numpy()\n",
    "        test_acc += np.mean(outputs == label.cpu().numpy())\n",
    "    return test_acc/len(test_dataloader),test_loss/len(test_dataloader)\n",
    "\n",
    "#change dataloader by yourself\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_len):\n",
    "        self.data=torch.rand((data_len,1,900,136))#B,C,T,V\n",
    "        self.label=torch.ones(data_len)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        data=self.data[idx]\n",
    "        label=self.label[idx]\n",
    "        return data,label\n",
    "#create adj\n",
    "adj = np.corrcoef(np.random.rand(136,170*900))\n",
    "np.save('adj.npy',adj,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop epoch: 366 Early stopping, best test acc: 1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "train_dataset=MyDataset(170)\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "test_dataset=MyDataset(10)\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=1)\n",
    "\n",
    "tra_acc,tra_loss,tes_acc,tes_loss=[],[],[],[]\n",
    "patience = 20\n",
    "early_stopping = EarlyStopping(patience, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss() # nn.BCELoss()\n",
    "net,optimizer = get_model('adj.npy')\n",
    "if_best = False\n",
    "edge_imp_all = []\n",
    "for epoch in range(1, 501):\n",
    "    acc,loss = train_model(net,optimizer,criterion,train_dataloader)\n",
    "    tra_acc.append(acc)\n",
    "    tra_loss.append(tra_loss)\n",
    "    acc,loss = test_model(net,criterion,test_dataloader)\n",
    "    tes_acc.append(acc)\n",
    "    tes_loss.append(loss)\n",
    "    if epoch>200:\n",
    "        for importance in net.edge_importance:\n",
    "            edge_importances = (torch.abs(importance)+torch.transpose(torch.abs(importance),0,1))*0.5\n",
    "            edge_imp = torch.squeeze(edge_importances.data).cpu().numpy()\n",
    "            edge_imp_all.append(edge_imp)\n",
    "        if_best = early_stopping(loss, net)#return True if early stop\n",
    "    if if_best:\n",
    "        best_test_acc = acc\n",
    "        torch.save(net.state_dict(),'saved.pt')\n",
    "    if early_stopping.early_stop:\n",
    "        edge_imp = np.array(edge_imp_all).mean(axis=0)\n",
    "        print('stop epoch:',epoch,\"Early stopping, best test acc:\",best_test_acc)\n",
    "        # 结束模型训练\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shelton",
   "language": "python",
   "name": "shelton"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
